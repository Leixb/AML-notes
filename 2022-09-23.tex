\section[A glimpse into Bayesian methods]{A glimpse into Bayesian methods (for supervised ML)}
\index{bayesian}

We have a data sample \(D = \{ x^i, y^i\}\quad i = 1, \dots, n\)
where \(x \in \mathcal{X} = \mathds{R}^d, y^i \in \mathcal{Y}\)
We consider a hypothesis space
\(\mathcal{F} \coloneqq \{ f_\theta (x), \theta \in \Theta \subset \mathds{R}^d \}\).

The Bayesian idea is not to consider the optimal solution
\(\hat{\theta}\) as a point solution, but as a set of possible solutions,
some of which are more likely (to be correct) than others.

The available data \(D\) serves to reduce the uncertainty of the
distribution.

The Bayesian machinery makes use of the Bayes formula.
%
\begin{align*}
	P(D \mid \theta) \tag{likelihood} \\
	P(\theta \mid D) \tag{posterior}  \\
	P(\theta) \tag{prior}          \\
	\int_\Theta P(D \mid \theta') P(\theta') d\theta' = P(D) \tag{EXPECTED \equiv EVIDENCE}
\end{align*}
%
\[
	P(\theta \mid D) = \frac{P(D \mid \theta) P(\theta)}
	{ \int_\Theta P(D \mid \theta') P(\theta') d\theta' }
\]

\subsection{Procedure}

\begin{quote}
	Modelling is choosing
\end{quote}

\begin{enumerate}
	\item
	      Collect the data \(D\)

	      \begin{enumerate}
		      \item
		            Decide the \emph{functional form of the models} \(f_\theta (x)\)
		      \item
		            Choose the \emph{prior} \(P(\theta)\) about the parameters
	      \end{enumerate}
	\item
	      Calculate the \emph{likelihood function} \(P(y \mid x, \theta)\) (The
	      probability of getting the data \(D\) for a specific value of
	      \(\theta\))
	\item
	      Calculate the \emph{posterior distribution} of \(\theta\)

	      \[
		      P(\theta \mid D) = \frac{P(\theta) \prod_{i=1}^n}{P(y^i \mid x^i, \theta)
			      {\int_\Theta d\theta' P(\theta')\prod_{i=1}^n} P(y^i \mid x^i, \theta')}
	      \]

	\item
	      Decide a method for making predictions (when new data \(x^0\) comes):

	      \begin{enumerate}
		      \item Eliminate the prior \(P(\theta)\) \textrightarrow{}
		            \(P(\theta  \mid D) \propto \mathcal{L}(\sigma ; D) \cdot P(\theta)\)

		            \begin{enumerate}
			            \item
			                  Then, the only thing that matters is the likelihood
			            \item
			                  You then find a set of parameters \(\theta\) that maximizes the
			                  likelihood function
			                  \(\hat{\theta}_{ML} = \argmax_{\theta \in \Theta} \mathcal{L}(\sigma ; D)\)
		            \end{enumerate}
		      \item
		            Half Bayesian
		            \(P(\theta \mid D) \propto \mathcal{L}(\sigma ; D) \cdot P(\theta)\)

		            \begin{enumerate}
			            \item
			                  \(\hat{\theta}_{MAP} = \argmax_{\theta \in \Theta} \mathcal{L}(\sigma ; D) \cdot P(\theta)\)
			                  (Maximum a posteriori)
			            \item
			                  Since we have a multiplication to minimize, we use logarithms.
			            \item
			                  It is then:
			                  \(\hat{\theta}_{MAP} = \argmax_{\theta \in \Theta} \log \mathcal{L}(\sigma ; D) + \log P(\theta)\)
		            \end{enumerate}
		      \item
		            Calculate the \emph{average of the posteriors} \(P(\theta \mid D)\)
                instead of the maximum. (average \textrightarrow{} expected value)

		            \begin{enumerate}
			            \item \(\hat{\theta}_{avg} = \int_\Theta \theta P(\theta \mid D) \; d\theta\)
			            \item In practice, this integral is intractable, we have to use
			                  numerical integration. Which is quite delicate.
		            \end{enumerate}
		      \item Fully Bayesian: you have to work with the full posterior.
		            \begin{enumerate}
			            \item You don't return any model. You return a distribution over models.
			            \item Since we have a distribution, we can compute confidence integrals
			                  (bayesian confidence intervals) (not in the scope of the course)
			            \item Suppose that a new data point comes, \(x^0\):

			                  \[P(y^0 \mid x^0, D) = \int_\Theta P(y^0 \mid x^0, \theta) P(\theta \mid D)\; d\theta
			                  \]

			                  In the first 2 cases, we obtain a single unique model.In all
			                  cases, the data is constant.
		            \end{enumerate}
	      \end{enumerate}
\end{enumerate}

\subsubsection{Fully worked example}

We depart from a data sample and face a regression task.

So \(x^i \in \mathds{R}^d,\; y^i \in \mathds{R}\) and we want to perform
\emph{linear regression}.
\begin{equation*}
	\mathcal{F}_{\text{linr}} \coloneqq \bigl\{
	x \mapsto f_\omega(x) = \omega^T x + \omega_0 \mid
	\omega \in \mathds{R}^d, \quad
	\omega_0 \in \mathds{R}
	\bigr\}
\end{equation*}

By convention \(\underbar{\omega} \coloneqq (\omega,\, \omega_0)\)

\begin{itemize}
	\item What loss function do we use?
	\item What kind of regularizer (penalty on model complexity) should I
	      use?
\end{itemize}

\begin{align*}
  y &= f_\omega(x) + \varepsilon \\
  \mathds{E}[\varepsilon] &= 0 \\
  \text{Var}(\varepsilon) &= \sigma^2 < \infty \\
  \text{Independence between }& x \text{ and }\varepsilon
\end{align*}

\paragraph{Procedure}

\begin{enumerate}
	\item For an arbitrary input \(x \in \mathds{R}^d\), we want to predict
	      \(y \in \mathds{R}\)
	      \begin{align*}
		      \varepsilon                      & \sim \mathcal{N}(0, \sigma^2)                                       \\
		      P(y \mid x,\, \underbar{\omega})   & = \mathcal{N}(y \mid f_{\underbar{\omega}}(x),\, \sigma^2)               \\
		      \beta                         & = \frac{1}{\sigma^2} \text{ (precision)}                            \\
		      P(\underbar{\omega})          & = \mathcal{N}(\underbar{\omega} ;\, 0 ,\, \Sigma)                       \\
		      \Sigma                        & \coloneqq \text{ covariance matrix (Not viable in practice, we use other)} \\
		      P(\underbar{\omega} \mid \alpha) & = \mathcal{N}(\underbar{\omega} ;\, 0 ,\,\sigma_{\omega}^2 I))         \\
		      \alpha                        & \coloneqq \frac{1}{\sigma_{\omega}^2}
	      \end{align*}

	      A parameter that controls other parameters is called a
	      \iemph{hyperparameter}. In this case, \(\sigma_\omega\) is an
	      hyperparameter.

	\item The \emph{likelihood function}

	      \[
		      \mathcal{L}(\underbar{\omega} ; \beta) = \prod_{i=1}^n P(y^i \mid x^i, \underbar{\omega}) =
		      \prod_{i=1}^n \mathcal{N}(y^i \mid f_{\underbar{\omega}}(x^i), \sigma^2)
	      \]

	\item The \iemph{posterior distribution}
\end{enumerate}

\[P(\underbar{\omega} \mid y, X, \alpha, \beta) = \frac{\mathcal{L}(\underbar{\omega}; \beta) P(\underbar{\omega} \mid \alpha)}
	{\int_{\mathds{R}} \mathcal{L}(\underbar{\omega}; \beta) P(\underbar{\omega} \mid \alpha) d\underbar{\omega}}
\]

\begin{recap}{}{}

\subparagraph{Model}

\[
	P(y \mid  X, \underbar{\omega}, \beta) = \mathcal{N}(y \mid f_{\underbar{\omega}}(x), \beta) =
	\sqrt{\frac{\beta}{2\pi}} \exp \left( -\frac{\beta}{2} (y - f_{\underbar{\omega}}(x))^2 \right)
\]

\subparagraph{Prior}

\[P(\underbar{\omega} \mid \alpha) = \mathcal{N}(\underbar{\omega} ; 0 , \sigma_{\omega}^2 I)) =
	\sqrt{\frac{\alpha}{2\pi}} \exp \left( -\frac{\alpha}{2} \underbar{\omega}^T \underbar{\omega} \right)
\]

\subparagraph{Result}

The posterior distribution turns out to be:

\[P(\underbar{\omega} \mid D) = \mathcal{N}(\underbar{\omega} ; \mu, \Sigma)
	\mu = \beta \Sigma X^T y
	\Sigma = \left( \alpha I + \beta X^T X \right)^{-1}
\]

\begin{enumerate}
	\item
	      Maximum likelihood: \(\hat{\underbar{\omega}} = (X^T X)^{-1} X^T y\)
	\item
	      Maximum posteriori: \(\hat{\underbar{\omega}} = ???\) (Standard ridge
	      regression)
	\item
	      Average posteriori: \(\hat{\underbar{\omega}} = ???\)
	\item
	      Full Bayesian: \(\hat{\underbar{\omega}} = ???\)
\end{enumerate}

\end{recap}
